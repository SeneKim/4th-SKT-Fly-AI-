# 생성형 AI

날짜: 2024년 1월 29일
태그: ML/AL

## Tokenizer

- **Token: 의미를 명시하는 최소한의 단위**
- 언어 모델이 한 번에 처리할 수 있는 기준이 된다.
- 보통 단어 * 1.3 정도가 Token의 개수로 나온다.

*Info - Open AI*

[](https://platform.openai.com/tokenizer)

## ChatGPT

**한계**

→ 21년도 9월에 학습을 멈춤. 최신 정보에 대해 알려주지 못한다.

→ 할루시네이션(Hallucination): 말을 생성하는 데에 의미가 있다. 아무 말이나 뱉는 것. 따라서 의미가 제대로 생성되지 않을 수도 있다. 답이 정확하게 output으로 나오지 않은 케이스

*GPT가 거짓말을 해요!*

**개선방안**

> **검색 엔진과 붙여서 사용하기**
> 

ex) Microsoft Bing + ChatGPT 4.0 

Microsoft Bing에 있는 Chat은 검색 기반으로 의미 생성, GPT 4 무료 사용 가능. 

## N-Shot Learning

Hallucination을 피할 수 있는 또 다른 방법.

- One shot: 한 번  example을 주는 것
- Zero shot: example을 주는 것
- Few shot: 여러 번 example을 주는 것

→ 매번 새로운 예시를 주어야 하기 때문에 Token 소모가 심하다. 

> **→ 모델은 고정하되 어떻게 잘 물어보느냐**
> 

## Fine tuning

내가 원하는 Domain의 데이터를 구해 해당 데이터의 지식을 Model에 집어 넣어 parameter을 재조정 하는 것

**※ 주의: 자주 변동 되는 데이터를 학습시키면 안된다.**

- 문제: 비용(COST)
    - GPU 자원의 필요
    - 기존 base모델이 저장되어야 하고 해당 모델의 운영비는 별도로 소모

---

## RAG(Retrieval Augmented Generation)

**“가장 주목 받고 있는 기법!”**

예시) pdf 챗봇 구축

1. 문서 업로드
2. 문서 분할
    - 업로드 된 모든 파일을 한꺼번에 input을 받을 수 없기 때문에 모델이 입력 받을 수 있는 사이즈로 분할한다.
3. 문서 임베딩
    - Vectorize
    - 모델이 이해할 수 있도록 문서를 수치화
4. 임베딩 검색
    - 질문과 연관성이 높은 문서 추출
5. 답변 생성

***→ Semantic Kernel, LangChain(RAG를 사용할 수 있는 Framework)***

---

## Streamlit을 통한 챗봇 App 배포

**Streamlit → 간단한 데이터 시각화 및 반응형 웹 생성 가능**

[Streamlit • A faster way to build and share data apps](https://streamlit.io/)

### 1. OpenAI API 접속
구성 한 번 살펴보기~
https://platform.openai.com/playground


### 2. API Key 받아와서 페르소나 주고 질문해보기

- pip install package

```python
pip install openai
pip install streamlit
```

- main code

```python
import openai

# openai api 키
OPENAI_API_KEY='KEYYYYYYYYYYYY'

# 접속하려는 주소
OPENAI_API_ENDPOINT='AZUREEEEEEEEEEEEEEEE'

# 클라우드에서 접속하기 때문에 type 명시 필요
OPENAI_API_TYPE = 'azure'

# 사용하려는 api version
OPENAI_API_VERSION='2023-05-15'

# open api 및 엔드 포인트 지정
openai.api_key = OPENAI_API_KEY
openai.azure_endpoint = OPENAI_API_ENDPOINT
openai.api_type = OPENAI_API_TYPE
openai.api_version = OPENAI_API_VERSION

# 질문하자
query = "Who is Helen Keller?"

# 결과 담기기
result = openai.chat.completions.create(
    # 내가 대화할 모델을 설정한다. 
    model = 'dev-model',
    
    # 대화의 온도를 설정해주어요
    temperature = 0,

    # 대화는 여러 번 주고 받기 때문에 list로 받는다. 
    # 페르소나 잡아주기: 내가 이야기할 gpt의 정체성, 방향성을 잡아주어야 한다. 
    messages= [
        # role은 모두 딕셔너리 타입!
        # system이라고 적으면 이후 적는 페르소나는 system에 모두 영향이 가게 됨
        {'role': 'system', 
         'content': 'You are a helpful assistant.'},

        # user의 페르소나 정의하기
        {'role': 'user', 
         'content': query}
    ]
)
print(result.choices[0].message.content)
```

```python
ChatCompletion(id='chatcmpl-8mFhsFHRDns0BdwTlXpsFEhdYE9CV', 
choices=[Choice(finish_reason='stop', 
index=0, 
logprobs=None, 
message=ChatCompletionMessage(
content='Helen Keller was an American author, political activist, and lecturer. She was the first deaf-blind person to earn a Bachelor of Arts degree. Despite being blind and deaf from a young age, she overcame these obstacles to become a well-known and influential advocate for people with disabilities. She is also known for her writings, including her autobiography, "The Story of My Life."', 
role='assistant', 
function_call=None, 
tool_calls=None))], 
created=1706510812, 
model='gpt-35-turbo', 
object='chat.completion', 
system_fingerprint='fp_7b3f466340', 
usage=CompletionUsage(completion_tokens=76, prompt_tokens=22, total_tokens=98))
```

+) 반복적으로 질문 주고 받아보기

```python
def make_response():
    query = input('Q: ')
    result = openai.chat.completions.create(
    # 내가 대화할 모델을 설정한다. 
    model = 'dev-model',
    temperature=0.5,
    # 대화는 여러 번 주고 받기 때문에 list로 받는다. 
    # 페르소나 잡아주기: 내가 이야기할 gpt의 정체성, 방향성을 잡아주어야 한다. 
    messages= [
        # role은 모두 딕셔너리 타입!
        # system이라고 적으면 이후 적는 페르소나는 system에 모두 영향이 가게 됨
        {'role': 'system', 
         'content': 'You are a helpful assistant.'},

        # user의 페르소나 정의하기
        {'role': 'user', 
         'content': query}
    ]
)
    print("A: ", result.choices[0].message.content)
    

while True:
    # stop with ctrl + c
    make_response()
```

---

### 3. streamlit 실행

**기본 화면 만들어보기**

- streamlit.py(basic)

```python
import streamlit
```

- Run 명령어

```python
# cmd 수행
streamlit run streamlit-00.py
```


아무 것도 없는 완전 기본 화면

**필요한 것을 구성할 때!**

여기서 검색해서 사용하기 

[API Reference - Streamlit Docs](https://docs.streamlit.io/library/api-reference)

**응답을 주고 싶을 수 있는 페이지 제작해보기**

- Code

```
import openai
import streamlit as st

# openai api 키
OPENAI_API_KEY='KEYYYYYYYYYYYY'

# 접속하려는 주소
OPENAI_API_ENDPOINT='AZUREEEEEEEEEEEEEEEE'

# 클라우드에서 접속하기 때문에 type 명시 필요
OPENAI_API_TYPE = 'azure'

# 사용하려는 api version
OPENAI_API_VERSION='2023-05-15'

# open api 및 엔드 포인트 지정
openai.api_key = OPENAI_API_KEY
openai.azure_endpoint = OPENAI_API_ENDPOINT
openai.api_type = OPENAI_API_TYPE
openai.api_version = OPENAI_API_VERSION
# header
st.header('Welcom to GPTBot',
          divider='rainbow')

# 일반 text 쓰기
st.write("Please give me any questions!")

# 사용자로부터 입력 받기
query = st.text_input('Q: ')

# 질문 실행을 위한 버튼 생성
# 또한 버튼이 눌렸는지 아닌지를 체크하기 위한 변수 지정
button_click = st.button("Run")

def make_response(question):
    result = openai.chat.completions.create(
    # 내가 대화할 모델을 설정한다. 
    model = 'dev-model',

    # 대화의 온도를 지정해보아요~
    temperature=0.5,

    # 대화는 여러 번 주고 받기 때문에 list로 받는다. 
    # 페르소나 잡아주기: 내가 이야기할 gpt의 정체성, 방향성을 잡아주어야 한다. 
    messages= [
        # role은 모두 딕셔너리 타입!
        # system이라고 적으면 이후 적는 페르소나는 system에 모두 영향이 가게 됨
        {'role': 'system', 
         'content': 'You are a helpful assistant.'},

        # user의 페르소나 정의하기
        {'role': 'user', 
         'content': question}
    ]
)
    return result.choices[0].message.content
    
# 일단은 한 번만 수행해보자
if button_click:
    st.write("A: ", make_response(query))
```


### 번외: AI Poet(시인)

- sample-01-AIpoem.py

```python
import openai
import streamlit as st

# openai api 키
OPENAI_API_KEY='KEYYYYYYYYYYYY'

# 접속하려는 주소
OPENAI_API_ENDPOINT='AZUREEEEEEEEEEEEEEEE'

# 클라우드에서 접속하기 때문에 type 명시 필요
OPENAI_API_TYPE = 'azure'

# 사용하려는 api version
OPENAI_API_VERSION='2023-05-15'

# open api 및 엔드 포인트 지정
openai.api_key = OPENAI_API_KEY
openai.azure_endpoint = OPENAI_API_ENDPOINT
openai.api_type = OPENAI_API_TYPE
openai.api_version = OPENAI_API_VERSION

# header
st.header('Welcome to AI Poem',
          divider='rainbow')

# 일반 text 쓰기
st.write("Let's make beautiful poems with me!")

# 사용자로부터 입력 받기
name = st.text_input('Enter your name: ')

# 이름을 입력 받았을 때만 다음 구문 실행
if (name):
    st.write("Hello " + name + '.')

subject = st.text_input("Enter subjects of your poem.")

contents = st.text_area("Enter the contents of your poem.")

# 질문 실행을 위한 버튼 생성
# 또한 버튼이 눌렸는지 아닌지를 체크하기 위한 변수 지정
button_click = st.button("Run")

def make_response():
    result = openai.chat.completions.create(
    # 내가 대화할 모델을 설정한다. 
    model = 'dev-model',

    # 대화의 온도를 지정해보아요~
    temperature=0.5,

    # 대화는 여러 번 주고 받기 때문에 list로 받는다. 
    # 페르소나 잡아주기: 내가 이야기할 gpt의 정체성, 방향성을 잡아주어야 한다. 
    messages= [
        # role은 모두 딕셔너리 타입!
        # system이라고 적으면 이후 적는 페르소나는 system에 모두 영향이 가게 됨
        {'role': 'system', 
         'content': 'You are a poet.'},

        # user의 페르소나 정의하기
        {'role': 'user', 
         'content': 'The Writer name is' + name},
        {'role': 'user', 
        'content': "The poem's subjects are" + subject},
        {'role': 'user', 
        'content': 'The contents of the poem' + contents},
        {'role': 'user', 
        'content': 'Please make a poem with this informations.'}
    ]
)
    return result.choices[0].message.content
    
# 일단은 한 번만 수행해보자
if button_click: 
    # loading 하는 것 구성해보기
    # 답변이 생성될 때까지 로딩 돌아가는 화면 구성
    with st.spinner('Please wait for seconds.'):
        st.write("<AI Generated Poem>")
        st.write(make_response())

				# 마지막에 done이라고 나오기!
        st.success('Done!')

