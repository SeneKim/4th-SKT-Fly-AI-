{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZSrR1jsEau9",
        "outputId": "cdb32236-13d7-4d77-f24d-483dac0ce116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/225.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/225.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.10.0 typing-extensions-4.9.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.17-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.84-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.17 langsmith-0.0.84 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Template 사용해보기"
      ],
      "metadata": {
        "id": "s_xTeJlPEoKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'KEY'\n",
        "os.environ['AZURE_OPENAI_ENDPOINT'] = 'ENDPOINT'\n",
        "os.environ['OPENAI_API_TYPE'] = 'azure'\n",
        "os.environ['OPENAI_API_VERSION'] = '2023-05-15'"
      ],
      "metadata": {
        "id": "VCmlAO9bFDRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import AzureOpenAI\n",
        "from langchain.chat_models import AzureChatOpenAI"
      ],
      "metadata": {
        "id": "1lcqRZiYFJzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureOpenAI(\n",
        "    deployment_name = 'dev-gpt-35-turbo-instruct',\n",
        "\n",
        "    # 제한을 걸어주어야 토큰 낭비가 되지 않는다.\n",
        "    # 만약 제한이 없다면 사용할 수 있는 토큰에서 계속 떠들고 있을\n",
        "    max_tokens = 1000\n",
        ")"
      ],
      "metadata": {
        "id": "yvhf5zxTFz_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 템플릿 정의하기\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "\n",
        "# 기본 query 정의\n",
        "string_prompt = PromptTemplate.from_template('Tell me a joke about {subject}')\n",
        "\n",
        "# 내가 어떤 주제를 넘기느냐에 따라 다양한 질문을 만들 수 있다.\n",
        "string_prompt_value = string_prompt.format_prompt(subject = 'soccer')\n",
        "\n",
        "# 질문 확인\n",
        "string_prompt_value.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iESyI3waGVhO",
        "outputId": "9b2a2742-6d77-4f12-ff73-4ee48f885d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = '''\n",
        "너는 요리사야. 내가 가지고 있는 재료들로 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해\n",
        "내가 가진 재료는 아래와 같아\n",
        "\n",
        "<재료>\n",
        "{재료}\n",
        "'''\n",
        "\n",
        "# {재료}부분을 갈아 낄 수 있도록 만들겠다.\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=['재료'],\n",
        "\n",
        "    # 위에서 정의한 템플릿 넣어주\n",
        "    template = template\n",
        ")\n",
        "\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xECZla20HMr1",
        "outputId": "4bb6212f-e541-4386-df6a-311e5eef594c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['재료'], template='\\n너는 요리사야. 내가 가지고 있는 재료들로 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해\\n내가 가진 재료는 아래와 같아\\n\\n<재료>\\n{재료}\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.format(재료='양파, 계란, 당근, 빵')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "nf1316FWIZbh",
        "outputId": "9f984daa-c152-49dd-b5a6-6d0eed3bf599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n너는 요리사야. 내가 가지고 있는 재료들로 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해\\n내가 가진 재료는 아래와 같아\\n\\n<재료>\\n양파, 계란, 당근, 빵\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 답을 출력해보기\n",
        "llm(prompt_template.format(재료='양파, 계란, 사과, 빵'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "wTFEuKD8I09E",
        "outputId": "12f259d2-e059-4337-d3e0-7c8e23fc0eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n추천 요리: 양파 계란볶음밥\\n\\n레시피:\\n1. 양파를 채 썰어준다.\\n2. 계란을 풀어서 소금과 후추로 간을 한다.\\n3. 팬에 식용유를 두르고 양파를 볶아준다.\\n4. 양파가 익으면 계란을 넣어서 볶아준다.\\n5. 계란이 익으면 빵을 큼직하게 잘라서 넣어준다.\\n6. 빵이 바싹 볶아질 때까지 볶아준다.\\n7. 사과를 껍질을 벗겨서 채 썰어준 뒤 마지막에 얹어준다.\\n8. 약간의 식초를 넣어서 마무리해주면 완성이다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 대화형 모델의 템플릿"
      ],
      "metadata": {
        "id": "Df3hbbUbN4x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import(\n",
        "    PromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "\n",
        "from langchain.schema import(\n",
        "    SystemMessage,\n",
        "    AIMessage,\n",
        "    HumanMessage\n",
        ")"
      ],
      "metadata": {
        "id": "eVsZ_SiFJJGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt = AzureChatOpenAI(\n",
        "    deployment_name = 'dev-gpt-35-turbo',\n",
        "    temperature = 0\n",
        ")\n",
        "\n",
        "# 시스템 메세지의 프롬프트 설정\n",
        "# 이전에 정의한 템플릿을 넣어줌\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "# 휴먼 메세지의 프롬프트 설정\n",
        "human_template = '{재료}'\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "# chat prompt template\n",
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    messages = [\n",
        "        system_message_prompt,\n",
        "        human_message_prompt\n",
        "    ])\n",
        "\n",
        "# 대화형 모델에서는 message를 뽑아서 넘겨주어야 동작할 수 있다.\n",
        "answer = chatgpt(chat_prompt.format_prompt(재료='치킨, 계란, 빵').to_messages())\n",
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDc52FbhOfKb",
        "outputId": "50d1afb7-0e0b-47e4-acc1-a1ac09bbc584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='가지고 있는 재료로 만들 수 있는 요리 중 하나는 \"치킨 샌드위치\"입니다. 아래는 치킨 샌드위치의 레시피입니다.\\n\\n[치킨 샌드위치 레시피]\\n재료:\\n- 치킨 가슴살 2조각\\n- 계란 2개\\n- 빵 4장\\n- 상추, 토마토, 양파 (선택적으로 추가 가능)\\n\\n조리 방법:\\n1. 치킨 가슴살을 소금과 후추로 조미료한 후 그릴이나 팬에서 구워주세요. 완전히 익을 때까지 약 5-7분 정도 소요됩니다.\\n2. 계란을 끓는 물에 넣고 7-8분 정도 삶아주세요. 그 후 찬물에 담가 식힌 뒤 껍질을 벗겨주세요.\\n3. 빵을 깨끗한 표면으로 준비해주세요. 필요에 따라 토스터기나 오븐에서 빵을 따뜻하게 해도 좋습니다.\\n4. 빵 한 장 위에 구운 치킨 가슴살을 올려주세요. 그 위에 삶은 계란을 얇게 슬라이스하여 올려주세요.\\n5. 상추, 토마토, 양파 등의 추가 재료를 원한다면 올려주세요.\\n6. 다른 한 장의 빵으로 샌드위치를 덮어주세요.\\n7. 샌드위치를 절반으로 잘라서 서빙하거나, 필요에 따라 추가적인 소스나 드레싱을 곁들여 즐겨주세요.\\n\\n이렇게 만들어진 치킨 샌드위치는 간편하면서도 맛있는 요리입니다. 즐거운 식사 되세요!')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few shot Learning"
      ],
      "metadata": {
        "id": "9kJk9d1kTHIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        'question' : '아이유로 삼행시를 지어줘',\n",
        "        'answer' : '''\n",
        "        아 아이유는\n",
        "        이 이상하고\n",
        "        유 유난히 좋다.\n",
        "        '''\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'question' : '이순신으로 삼행시를 지어줘',\n",
        "        'answer' : '''\n",
        "        이 이순신 장군은\n",
        "        순 순수히 내어줄 것 같았던 조선의 바다를\n",
        "        신 신의와 충의의 마음으로 지켜냈다.\n",
        "        '''\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "CxrhJGY8RnhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 template\n",
        "example_prompt = PromptTemplate(\n",
        "    # 위 프롬프트에서 포함된 key 요소를 적어주어야 한다.\n",
        "    input_variables=['question', 'answer'],\n",
        "    template='Question: {question}\\n{answer}'\n",
        ")\n",
        "\n",
        "# sample template test\n",
        "# examples에 명명한 탬플릿이 잘 들어갔는지 확인해보자\n",
        "# 여기서 넘길 때 탬플릿의 값을 넘기는 것이 아니라 주소를 넘겨주어야한다.\n",
        "# **을 붙여주면 해당 변수의 주소를 넘겨준다\n",
        "print(example_prompt.format(**examples[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa_hOqshU0ay",
        "outputId": "9c3dd868-0cd2-4a17-bce0-186404c752e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 아이유로 삼행시를 지어줘\n",
            "\n",
            "        아 아이유는\n",
            "        이 이상하고\n",
            "        유 유난히 좋다.\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fewshot learning을 위한 탬플릿 만들기\n",
        "prompt = FewShotPromptTemplate(\n",
        "    # 예시를 지정해주어야한다.\n",
        "    examples = examples,\n",
        "    example_prompt = example_prompt,\n",
        "    suffix = 'Question: {input}',\n",
        "    # 입력받을 값\n",
        "    input_variables = ['input']\n",
        ")"
      ],
      "metadata": {
        "id": "Dcy_uugHV-JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fewshot을 거치지 않은 것\n",
        "llm.invoke('손흥민으로 삼행시를 지어줘')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b-urfEKzXm0n",
        "outputId": "ddfd280f-1e15-498a-a0c0-c034dac8a917"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n손흥민은 영웅이요\\n축구는 그의 천국\\n매 경기마다 화려한\\n그의 발놀림은 정말 신기해'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example 뒤에 input이 붙는 것\n",
        "# 프롬프트 만들기\n",
        "prompt.format(input = '손흥민으로 삼행시를 지어줘')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "qzmMX57kXy5R",
        "outputId": "999562c9-6c1a-4d19-d9e8-257965a6d339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Question: 아이유로 삼행시를 지어줘\\n\\n        아 아이유는\\n        이 이상하고\\n        유 유난히 좋다.\\n        \\n\\nQuestion: 이순신으로 삼행시를 지어줘\\n\\n        이 이순신 장군은\\n        순 순수히 내어줄 것 같았던 조선의 바다를\\n        신 신의와 충의의 마음으로 지켜냈다.\\n        \\n\\nQuestion: 손흥민으로 삼행시를 지어줘'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt.format(input = '손흥민으로 삼행시를 지어줘')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XtQS8FMYBqy",
        "outputId": "86ba5840-8069-49a3-de4e-2ecd0a8720f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "        손 손흥민은\n",
            "        흥 흥미로운 축구의 재능을 갖고\n",
            "        민 민처럼 열심히 뛰며 나라를 대표한다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noS-XlEaYO_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
